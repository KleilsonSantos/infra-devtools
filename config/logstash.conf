# ================================================================================
# ğŸ“Š Logstash Configuration
# ğŸ‘¨â€ğŸ’» Author: Kleilson Santos
# ğŸ“… Created: 2025-11-07
#
# ğŸ“– Purpose: Pipeline for processing, filtering and enriching logs
#
# ================================================================================

# INPUT: Receive logs from Filebeat
input {
  beats {
    port => 5000
    host => "0.0.0.0"
  }
}

# FILTER: Process and enrich logs
filter {
  # Parse JSON logs if present
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "parsed"
    }
  }

  # Extract container information
  if [host][name] {
    mutate {
      add_field => { "container_name" => "%{[host][name]}" }
    }
  }

  # Add timestamp
  mutate {
    add_field => { "log_timestamp" => "%{@timestamp}" }
  }

  # Remove unnecessary fields to save space
  mutate {
    remove_field => [ "[host][containerized]", "[agent][ephemeral_id]" ]
  }

  # Add environment information
  mutate {
    add_field => { "environment" => "development" }
    add_field => { "log_source" => "docker" }
  }

  # Parse application logs (optional pattern matching)
  grok {
    match => {
      "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{DATA:level}\] %{GREEDYDATA:log_message}"
    }
    tag_on_failure => []
  }
}

# OUTPUT: Send to Elasticsearch
output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }

  # Also output to stdout for debugging
  stdout {
    codec => rubydebug
  }
}
