# üß™ APM Integration Guide - Observability 3 Pillars

> Complete integration of Metrics, Logs, and Traces in Grafana for Application Performance Monitoring

## üìë √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura](#arquitetura)
3. [Quick Start](#quick-start)
4. [Configura√ß√£o de Datasources](#configura√ß√£o-de-datasources)
5. [Dashboards](#dashboards)
6. [Correla√ß√£o de Dados](#correla√ß√£o-de-dados)
7. [Alertas e SLO](#alertas-e-slo)
8. [Troubleshooting](#troubleshooting)

---

## Vis√£o Geral

### O que √© APM?

APM (Application Performance Monitoring) √© a pr√°tica de coletar, agregar e analisar dados sobre o desempenho, disponibilidade e comportamento de aplica√ß√µes.

### 3 Pilares da Observabilidade

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     OBSERVABILIDADE - 3 PILARES INTEGRADOS         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                     ‚îÇ
‚îÇ  üìä M√âTRICAS (Prometheus)                          ‚îÇ
‚îÇ  ‚îî‚îÄ O QU√ä: Quantidades mensur√°veis                 ‚îÇ
‚îÇ     ‚îú‚îÄ CPU, Memory, Disk                           ‚îÇ
‚îÇ     ‚îú‚îÄ Request Rate, Error Rate                    ‚îÇ
‚îÇ     ‚îú‚îÄ Latency (P50, P95, P99)                     ‚îÇ
‚îÇ     ‚îî‚îÄ Custom metrics                              ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  üìã LOGS (Elasticsearch + Kibana)                  ‚îÇ
‚îÇ  ‚îî‚îÄ POR QU√ä: Eventos detalhados                    ‚îÇ
‚îÇ     ‚îú‚îÄ Application logs                            ‚îÇ
‚îÇ     ‚îú‚îÄ Error stacktraces                           ‚îÇ
‚îÇ     ‚îú‚îÄ User actions                                ‚îÇ
‚îÇ     ‚îî‚îÄ System events                               ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  üîÑ TRACES (Jaeger + OpenTelemetry)                ‚îÇ
‚îÇ  ‚îî‚îÄ COMO: Jornada completa da requisi√ß√£o           ‚îÇ
‚îÇ     ‚îú‚îÄ Request flow across services                ‚îÇ
‚îÇ     ‚îú‚îÄ Dependency mapping                          ‚îÇ
‚îÇ     ‚îú‚îÄ Latency breakdown                           ‚îÇ
‚îÇ     ‚îî‚îÄ Error propagation                           ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê    ‚îÇ
‚îÇ  üéØ CORRELA√á√ÉO: Juntar os 3 para:                   ‚îÇ
‚îÇ     ‚Ä¢ Root cause analysis                          ‚îÇ
‚îÇ     ‚Ä¢ Performance optimization                     ‚îÇ
‚îÇ     ‚Ä¢ Incident response                            ‚îÇ
‚îÇ     ‚Ä¢ Proactive monitoring                         ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Por que integrar?

Isolados:
```
‚ùå M√©trica alta ‚Üí Qual servi√ßo?
‚ùå Log de erro ‚Üí De qual requisi√ß√£o?
‚ùå Trace lento ‚Üí Por que?
```

Integrados:
```
‚úÖ M√©trica alta ‚Üí Ver logs correlatos ‚Üí Analisar trace detalhado
‚úÖ Error log ‚Üí Buscar trace por correlation ID ‚Üí Ver contexto completo
‚úÖ Trace lento ‚Üí Verificar m√©tricas ‚Üí Investigar logs espec√≠ficos
```

---

## Arquitetura

### Fluxo de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   APLICA√á√ïES                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  Emite:                                                    ‚îÇ
‚îÇ  ‚Ä¢ M√©tricas ‚Üí Prometheus exposition format                ‚îÇ
‚îÇ  ‚Ä¢ Logs ‚Üí stdout/stderr ‚Üí Filebeat                        ‚îÇ
‚îÇ  ‚Ä¢ Traces ‚Üí OpenTelemetry protocol                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì                    ‚Üì                    ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇPrometheus         ‚îÇFilebeat  ‚îÇ        ‚îÇJaeger    ‚îÇ
    ‚îÇ:9090   ‚îÇ         ‚îÇAgent  ‚îÇ        ‚îÇAgent ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                   ‚îÇ                    ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇES/Thanos         ‚îÇLogstash   ‚îÇ        ‚îÇCollector  ‚îÇ
    ‚îÇStorage  ‚îÇ         ‚îÇPipeline   ‚îÇ        ‚îÇStorage    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                   ‚îÇ                    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   GRAFANA   ‚îÇ
              ‚îÇ  Dashboard  ‚îÇ
              ‚îÇ             ‚îÇ
              ‚îÇ ‚Ä¢ Datasources
              ‚îÇ   ‚îú‚îÄ Prometheus (Metrics)
              ‚îÇ   ‚îú‚îÄ Elasticsearch (Logs)
              ‚îÇ   ‚îî‚îÄ Jaeger (Traces)
              ‚îÇ
              ‚îÇ ‚Ä¢ Dashboards
              ‚îÇ   ‚îú‚îÄ Metrics overview
              ‚îÇ   ‚îú‚îÄ Traces overview
              ‚îÇ   ‚îú‚îÄ Logs analysis
              ‚îÇ   ‚îî‚îÄ Integrated APM
              ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Integra√ß√£o em Grafana

```
Grafana Datasources Configuration:
‚îú‚îÄ Prometheus (M√©tricas)
‚îÇ  ‚îî‚îÄ Endpoint: http://prometheus:9090
‚îÇ
‚îú‚îÄ Elasticsearch (Logs)
‚îÇ  ‚îú‚îÄ Endpoint: http://elasticsearch:9200
‚îÇ  ‚îú‚îÄ Index: logs-*
‚îÇ  ‚îî‚îÄ Time Field: @timestamp
‚îÇ
‚îî‚îÄ Jaeger (Traces)
   ‚îú‚îÄ Endpoint: http://jaeger-collector:16686
   ‚îî‚îÄ Integrations:
      ‚îú‚îÄ Traces ‚Üí Logs (via Correlation ID)
      ‚îî‚îÄ Traces ‚Üí Metrics (via Service Names)
```

---

## Quick Start

### 1Ô∏è‚É£ Iniciar Stack Completa

```bash
# Iniciar todos os servi√ßos
docker-compose up -d

# Ou iniciar apenas observabilidade
docker-compose up -d \
  prometheus grafana \
  elasticsearch kibana logstash filebeat \
  jaeger-collector jaeger-agent
```

### 2Ô∏è‚É£ Verificar Integra√ß√µes

```bash
# Grafana
open http://localhost:3001

# Prometheus
open http://localhost:9090

# Kibana
open http://localhost:5601

# Jaeger UI
open http://localhost:16686
```

### 3Ô∏è‚É£ Verificar Datasources em Grafana

1. V√° em: **Grafana > Settings > Data Sources**
2. Voc√™ deve ver:
   - ‚úÖ **Prometheus** (M√©tricas)
   - ‚úÖ **Elasticsearch** (Logs)
   - ‚úÖ **Jaeger** (Traces)

Se algum estiver faltando, configure manualmente (veja pr√≥xima se√ß√£o).

### 4Ô∏è‚É£ Acessar Dashboards

Em Grafana:
- **Menu > Dashboards > Observability** (pasta auto-criada)
- Voc√™ deve ver:
  - üîÑ APM - Traces Overview
  - üß™ Observability - Metrics + Logs + Traces Integration

---

## Configura√ß√£o de Datasources

### Configura√ß√£o Autom√°tica

Os datasources s√£o configurados automaticamente via:

```yaml
# grafana/provisioning/datasources.yml
datasources:
  - name: Prometheus
    type: prometheus
    url: http://prometheus:9090

  - name: Elasticsearch
    type: elasticsearch
    url: http://elasticsearch:9200

  - name: Jaeger
    type: jaeger
    url: http://jaeger-collector:16686
```

### Configura√ß√£o Manual (se necess√°rio)

**Se o arquivo de provisioning n√£o funcionar:**

1. **Adicionar Prometheus:**
   - Grafana > Settings > Data Sources > Add
   - Type: Prometheus
   - URL: http://prometheus:9090
   - Click Save & Test

2. **Adicionar Elasticsearch:**
   - Type: Elasticsearch
   - URL: http://elasticsearch:9200
   - Index name: logs-*
   - Time field: @timestamp
   - Click Save & Test

3. **Adicionar Jaeger:**
   - Type: Jaeger
   - URL: http://jaeger-collector:16686
   - Click Save & Test

### Verificar Conex√£o

```bash
# Prometheus
curl http://localhost:9090/api/v1/targets

# Elasticsearch
curl http://localhost:9200/_cluster/health

# Jaeger
curl http://localhost:16686/api/services
```

---

## Dashboards

### Dashboard 1: APM - Traces Overview

**Prop√≥sito:** Visualizar traces em tempo real e an√°lise de performance

**Panels:**
1. **Recent Traces** - √öltimas 20 requisi√ß√µes com dura√ß√£o
2. **Error Rate (5m window)** - Taxa de erro ao longo do tempo
3. **Traces Per Second** - Throughput do sistema
4. **Request Latency (P50/P95/P99)** - Distribui√ß√£o de lat√™ncia

**Como Usar:**
```
1. Abra dashboard
2. Procure por traces problem√°ticas (alto tempo, erros)
3. Clique em uma trace para detalhar
4. Veja timeline de spans
5. Correlacione com logs via Correlation ID
```

### Dashboard 2: Observability - Metrics + Logs + Traces Integration

**Prop√≥sito:** Vis√£o integrada de toda a observabilidade

**Panels:**
1. **System Health** - Sa√∫de geral do sistema
2. **Memory Status** - Utiliza√ß√£o de mem√≥ria
3. **Error Count (24h)** - Total de erros nas √∫ltimas 24h
4. **Traced Services** - Quantos servi√ßos est√£o sendo rastreados
5. **Request Rate by Method & Status** - Taxa de requisi√ß√µes por tipo
6. **Log Levels Over Time** - Distribui√ß√£o de n√≠veis de log
7. **Error Traces (Last 50)** - √öltimas 50 traces com erro

**Como Usar:**
```
1. Monitorar sa√∫de geral do sistema
2. Identificar spikes de erro
3. Correlacionar com logs/traces
4. Usar como "status page" da infraestrutura
```

---

## Correla√ß√£o de Dados

### 1. Traces ‚Üí Logs

**Como funciona:**
- Cada trace tem um `trace_id` √∫nico
- Logs correlatos tamb√©m t√™m esse `trace_id`
- Grafana pode linkar traces para logs autom√°ticamente

**Configurar linkagem:**

No datasource Jaeger, adicionar:
```yaml
tracesToLogs:
  datasourceUid: 'Elasticsearch'  # UUID do datasource Elasticsearch
  tags: ['trace_id']              # Tags para procurar
  mappedFields:
    - source: 'trace_id'          # Campo no trace
      target: 'trace_id'          # Campo no log
```

**Usar:**
```
1. Abra uma trace em Jaeger
2. Veja campos: trace_id, span_id, etc.
3. Procure por esse trace_id em Logs
4. Veja logs correlatos ordenados por timestamp
```

### 2. Traces ‚Üí M√©tricas

**Como funciona:**
- Extrair m√©tricas de traces (lat√™ncia, erro rate)
- Correlacionar com m√©tricas do Prometheus

**Exemplo de query:**
```promql
# Lat√™ncia do servi√ßo X (do Prometheus)
histogram_quantile(0.99, sum(rate(span_duration_bucket{service="api"}[5m])) by (le))

# Trace do servi√ßo X (do Jaeger)
# Buscar traces com service="api" e duration > P99
```

**Usar para:**
- Investigar por que lat√™ncia subiu
- Correlacionar com CPU/memory
- An√°lise de causa raiz

### 3. Logs ‚Üí Traces

**Como funciona:**
- Se um log tem `trace_id`, clickar nele vai para o Jaeger
- Grafana configura links autom√°ticos

**Configurar:**
```yaml
# No datasource Elasticsearch:
jsonData:
  traceLinkFields: ['trace_id']
  traceLinkUrl: 'http://jaeger-collector:16686/trace/${trace_id}'
```

---

## Alertas e SLO

### 1. Alertas por M√©trica

**Em Grafana:**
```
1. Dashboard > Panel > Edit
2. Alert tab
3. Configure:
   - Condition: Error Rate > 5%
   - Duration: For 5m
   - Notification: Send to Slack
```

**Exemplos de alertas:**

```yaml
groups:
  - name: apm_alerts
    rules:
      # Error rate alto
      - alert: HighErrorRate
        expr: rate(traces_error_total[5m]) > 0.05
        for: 5m

      # Lat√™ncia alta
      - alert: HighLatency
        expr: histogram_quantile(0.99, rate(span_duration_bucket[5m])) > 1000
        for: 5m

      # Servi√ßo down
      - alert: ServiceDown
        expr: up{job="api"} == 0
        for: 1m
```

### 2. SLO (Service Level Objectives)

**Definir SLO:**
```
API Service:
‚îú‚îÄ Availability: 99.9%   (max 43 minutes/month downtime)
‚îú‚îÄ Latency P99: < 500ms  (99% of requests < 500ms)
‚îú‚îÄ Error Rate: < 0.1%    (max 0.1% errors)
```

**Configurar em Grafana:**

1. **Criar metric:**
   ```promql
   # Availability
   sum(rate(http_requests_total{status=~"2.."}[5m])) /
   sum(rate(http_requests_total[5m]))
   ```

2. **Criar dashboard panel:**
   ```
   - Query: metric acima
   - Threshold: 99.9%
   - Colorir: green se ‚â• 99.9%, red se < 99.9%
   ```

3. **Setup alertas:**
   - Se < 99.9%, trigger alert
   - Notify oncall engineer

---

## Troubleshooting

### ‚ùå Datasources n√£o conectam

**Problema:** Datasource shows "Error"

```bash
# Verificar conectividade
curl http://prometheus:9090/api/v1/targets
curl http://elasticsearch:9200/_cluster/health
curl http://jaeger-collector:16686/api/services

# Se falhar, verificar network
docker network inspect infra-default-shared-net
```

**Solu√ß√£o:**
- Verificar se containers est√£o rodando: `docker ps`
- Verificar logs: `docker logs <container>`
- Reiniciar datasource em Grafana

### ‚ùå Dashboards em branco

**Problema:** Panels n√£o mostram dados

```
1. Verificar datasource est√° selecionado (dropdown)
2. Verificar query est√° correta (Edit panel)
3. Verificar dados existem no datasource:
   - Prometheus: http://localhost:9090/graph
   - Elasticsearch: http://localhost:5601
   - Jaeger: http://localhost:16686
```

**Solu√ß√£o:**
- Se n√£o h√° dados, instrumentar aplica√ß√£o para gerar dados
- Aguardar alguns minutos para dados aparecer
- Verificar timerange do dashboard

### ‚ùå Correla√ß√£o n√£o funciona

**Problema:** N√£o consigo ir de Trace para Log

**Causa comum:** `trace_id` campo diferente em cada sistema

```
Jaeger: traceID
Elasticsearch: trace_id
Prometheus: trace_id

‚Üí Ajustar configura√ß√£o de mapping
```

**Solu√ß√£o:**
1. Edit Jaeger datasource
2. Configure tracesToLogs
3. Mapear campos corretamente:
   ```
   source: "traceID"    (Jaeger)
   target: "trace_id"   (Elasticsearch)
   ```

### ‚ùå Performance lenta

**Se Grafana/dashboards lentos:**

1. **Reduzir per√≠odo de dados:**
   - Mudar timerange para 1h ao inv√©s de 7d
   - Usar sampling em traces

2. **Desabilitar alguns panels:**
   - Muito pesado: Error Traces (pode ter 1000+ traces)
   - Filtrar dados: `tags="error=true"` ao inv√©s de tudo

3. **Aumentar recursos:**
   ```yaml
   # docker-compose.yml
   grafana:
     mem_limit: 2G  # Aumentar de 1G
     memswap_limit: 2G
   ```

---

## Refer√™ncia R√°pida

### Makefile Commands

N√£o h√° comandos espec√≠ficos para APM, use docker-compose diretamente:

```bash
# Iniciar stack
docker-compose up -d

# Parar
docker-compose down

# Ver logs
docker logs infra-default-grafana
docker logs infra-default-prometheus
docker logs infra-default-elasticsearch
```

### URLs

```
üñ•Ô∏è  Grafana (Dashboards):     http://localhost:3001
üìä Prometheus (M√©tricas):    http://localhost:9090
üìã Kibana (Logs):            http://localhost:5601
üîÑ Jaeger UI (Traces):       http://localhost:16686
```

### Usu√°rios Padr√£o

```
Grafana:
  Username: admin (ou configurado em .env)
  Password: admin (ou configurado em .env)

Kibana:
  Username: elastic
  Password: changeme

Jaeger:
  (Sem autentica√ß√£o padr√£o)
```

### Environment Variables (em .env)

```bash
# Grafana
GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=admin
GF_AUTH_ANONYMOUS_ENABLED=true
GF_AUTH_DISABLE_LOGIN_FORM=false

# Elasticsearch
ELASTIC_PASSWORD=changeme
ES_JAVA_OPTS=-Xms512m -Xmx512m

# Prometheus (default no docker-compose)
# Logstash (configurado para Elasticsearch)
# Jaeger (default)
```

---

## Next Steps

1. **Instrumentar aplica√ß√µes:**
   - Adicionar OpenTelemetry SDK
   - Gerar m√©tricas, logs, traces
   - Veja TRACING-GUIDE.md para exemplos

2. **Criar alertas customizados:**
   - Definir SLOs espec√≠ficos
   - Setup notifica√ß√µes (Slack, PagerDuty)
   - Auto-remediation rules

3. **Otimizar dashboards:**
   - Adicionar visualiza√ß√µes customizadas
   - Criar alerting rules
   - Setup automation

4. **Monitoramento cont√≠nuo:**
   - Daily reviews de alertas
   - Weekly SLO reviews
   - Mensal incident post-mortems

---

<p align="center">
  <b>Observabilidade Integrada = Visibilidade Total = Confian√ßa em Produ√ß√£o</b><br>
  <b>üöÄ by Kleilson Santos</b>
</p>
