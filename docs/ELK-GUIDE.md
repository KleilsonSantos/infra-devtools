# ðŸ“Š ELK Stack Guide - Complete Logging Solution

> Elasticsearch + Logstash + Kibana: Centralized logging, searching, and analytics

## ðŸ“‘ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura](#arquitetura)
3. [Quick Start](#quick-start)
4. [Elasticsearch](#elasticsearch)
5. [Kibana](#kibana)
6. [Logstash](#logstash)
7. [Filebeat](#filebeat)
8. [Queries e AnÃ¡lise](#queries-e-anÃ¡lise)
9. [Performance Tuning](#performance-tuning)
10. [Troubleshooting](#troubleshooting)

---

## VisÃ£o Geral

### O que Ã© ELK Stack?

O ELK Stack Ã© uma soluÃ§Ã£o completa de logging baseada em trÃªs componentes principais:

- **Elasticsearch:** Motor de busca distribuÃ­do para armazenar e indexar logs
- **Logstash:** Pipeline de processamento para coletar, processar e enriquecer dados
- **Kibana:** Interface de visualizaÃ§Ã£o e anÃ¡lise de dados

### Por que vocÃª precisa?

Sem logs centralizados:
- âŒ Logs perdidos quando container reinicia
- âŒ ImpossÃ­vel debugar problemas em produÃ§Ã£o
- âŒ Sem correlaÃ§Ã£o entre serviÃ§os
- âŒ Sem histÃ³rico de eventos

Com ELK Stack:
- âœ… RetenÃ§Ã£o de 30 dias de logs
- âœ… Busca rÃ¡pida e poderosa
- âœ… VisualizaÃ§Ãµes e dashboards
- âœ… Alertas baseados em padrÃµes
- âœ… CorrelaÃ§Ã£o cross-service

---

## Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCKER CONTAINERS                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  App Logs   â”‚  â”‚ App Logs    â”‚  â”‚ App Logs    â”‚    â”‚
â”‚  â”‚ (stdout)    â”‚  â”‚ (stdout)    â”‚  â”‚ (stdout)    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                â”‚                â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                          â”‚                            â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚         â”‚  Docker Container Logs          â”‚           â”‚
â”‚         â”‚  (/var/lib/docker/containers)   â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                          â”‚                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚  Filebeat   â”‚ (Log Shipper)
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚  Logstash   â”‚ (Processor)
                    â”‚  Pipeline   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
   â”‚   ES    â”‚      â”‚   Kibana   â”‚     â”‚ Alerter â”‚
   â”‚ Storage â”‚      â”‚  Analytics â”‚     â”‚ Trigger â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados

1. **Containers** produzem logs (stdout/stderr)
2. **Filebeat** coleta logs dos containers
3. **Logstash** processa, filtra e enriquece
4. **Elasticsearch** armazena e indexa
5. **Kibana** visualiza e analisa

---

## Quick Start

### 1ï¸âƒ£ Iniciar ELK Stack

```bash
# Iniciar todos os serviÃ§os (incluindo ELK)
docker-compose up -d

# Ou iniciar apenas ELK
docker-compose up -d elasticsearch logstash kibana filebeat
```

### 2ï¸âƒ£ Inicializar

```bash
# Criar index patterns, polÃ­ticas de retenÃ§Ã£o
make elk-init
```

### 3ï¸âƒ£ Verificar Status

```bash
make elk-verify
```

### 4ï¸âƒ£ Acessar Kibana

Abra no navegador: **http://localhost:5601**

---

## Elasticsearch

### O que Ã©?

Motor de busca distribuÃ­do que armazena e indexa logs em documentos JSON.

### Endpoints Ãšteis

```bash
# Health check
curl http://localhost:9200/_cluster/health

# List indexes
curl http://localhost:9200/_cat/indices?v

# Index stats
curl http://localhost:9200/_stats

# Search logs
curl -X GET "http://localhost:9200/logs-*/_search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": {
      "match": {
        "message": "error"
      }
    }
  }'
```

### Index Management

```bash
# Ver Ã­ndices
make elk-indexes

# Ver estatÃ­sticas
make elk-stats

# Limpar Ã­ndices antigos (>30 dias)
make elk-cleanup
```

### ConfiguraÃ§Ã£o

No `docker-compose.yml`:
- **Memory:** 512MB (ajustÃ¡vel)
- **Discovery:** Single node (produÃ§Ã£o: cluster)
- **Security:** Desativado (ativar em produÃ§Ã£o)
- **RetenÃ§Ã£o:** 30 dias (configurÃ¡vel)

---

## Kibana

### O que Ã©?

Interface visual para explorar, visualizar e analisar logs armazenados no Elasticsearch.

### Features

âœ… **Discover:** Explorar logs em tempo real
âœ… **Visualizations:** GrÃ¡ficos, mÃ©tricas, tabelas
âœ… **Dashboards:** PainÃ©is customizados
âœ… **Alerts:** NotificaÃ§Ãµes automÃ¡ticas
âœ… **Dev Tools:** Console para queries

### Acessar

- **URL:** http://localhost:5601
- **UsuÃ¡rio:** elastic (se seguranÃ§a estiver ativa)
- **Senha:** changeme

### Primeiros Passos

1. Acesse http://localhost:5601
2. VÃ¡ em **Stack Management** > **Index Patterns**
3. Create index pattern: `logs-*`
4. Set time field: `@timestamp`
5. VÃ¡ em **Discover** para ver logs

### Queries (KQL - Kibana Query Language)

```
# Buscar erro
message: "error"

# Buscar por container
container.name: "postgres"

# Buscar por severity
level: "ERROR"

# Buscar por range de tempo
@timestamp > now-1h

# Combinar condiÃ§Ãµes
level: "ERROR" AND container.name: "api"
```

---

## Logstash

### O que Ã©?

Pipeline de processamento que coleta, filtra, transforma e enriquece logs.

### Arquitetura do Pipeline

```
Input (Filebeat)
    â†“
Filter (Parse, Enrich, Transform)
    â†“
Output (Elasticsearch)
```

### ConfiguraÃ§Ã£o

Localizado em: `config/logstash.conf`

```ruby
# INPUT: Recebe logs do Filebeat
input {
  beats {
    port => 5000
  }
}

# FILTER: Processa logs
filter {
  # Parse JSON
  json { source => "message" }

  # Extract fields
  grok { match => { "message" => "..." } }

  # Add metadata
  mutate { add_field => { "env" => "production" } }
}

# OUTPUT: Envia para Elasticsearch
output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }
}
```

### Plugins Instalados

- `logstash-filter-json` - Parse JSON
- `logstash-filter-grok` - Pattern matching
- `logstash-filter-mutate` - Modify fields
- `logstash-output-elasticsearch` - ES output

### Monitorar Logstash

```bash
# Ver logs
make elk-logs

# Check metrics (Port 9600)
curl http://localhost:9600/_node/stats/jvm
```

---

## Filebeat

### O que Ã©?

Lightweight log shipper que coleta logs de containers Docker e os envia para Logstash.

### ConfiguraÃ§Ã£o

Localizado em: `config/filebeat.yml`

```yaml
filebeat.inputs:
  - type: container
    paths:
      - '/var/lib/docker/containers/*/*.log'
    json.message_key: log
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"

output.logstash:
  hosts: ["logstash:5000"]
```

### Recursos

- âœ… Coleta de Docker container logs
- âœ… Parsing JSON automÃ¡tico
- âœ… Metadata do container
- âœ… Backpressure handling
- âœ… Low resource usage

### Metrics

Filebeat expÃµe mÃ©tricas no port **5066**:

```bash
curl http://localhost:5066/stats
```

---

## Queries e AnÃ¡lise

### KQL (Kibana Query Language)

#### Exemplos BÃ¡sicos

```
# Buscar texto
message: "connection error"

# Buscar por campo
level: "ERROR"
container.name: "postgres"

# Operadores lÃ³gicos
level: "ERROR" AND service: "api"
level: "ERROR" OR level: "WARN"

# NegaÃ§Ã£o
NOT message: "health check"

# Wildcard
container.name: "postgres*"

# Range
@timestamp >= now-1h
http.status: >= 500
```

#### Exemplos Complexos

```
# Erros no Ãºltimo 1 hora
level: "ERROR" AND @timestamp > now-1h

# RequisiÃ§Ãµes lentas
http.response_time > 5000 AND @timestamp > now-30m

# Erros de conexÃ£o por serviÃ§o
message: "Connection refused" | stats count() by container.name

# Taxa de erro por hora
level: "ERROR" | stats count() by @timestamp
```

### AgregaÃ§Ãµes

```
# Contar erros por container
message: "error" | stats count() by container.name

# Valor mÃ¡ximo de latÃªncia
http.response_time | stats max(http.response_time)

# Percentil
http.response_time | stats percentiles(http.response_time)

# Cardinality
container.id | stats cardinality(container.id)
```

### VisualizaÃ§Ãµes

1. **Discover:** Explorar logs brutos
2. **Bar Chart:** Contar eventos
3. **Line Chart:** TendÃªncias ao longo do tempo
4. **Pie Chart:** DistribuiÃ§Ã£o
5. **Metric:** Valor Ãºnico
6. **Table:** Dados estruturados

---

## Performance Tuning

### Elasticsearch

```bash
# Aumentar heap memory
# No docker-compose.yml:
environment:
  - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
```

### Logstash

```bash
# Ajustar batch size
output {
  elasticsearch {
    batch_size => 5000  # Default: 2048
  }
}
```

### Filebeat

```bash
# Aumentar workers
output.logstash:
  worker: 4  # Default: 1
  batch_size: 4096
```

### Index Optimization

```bash
# ForÃ§ar merge
curl -X POST "http://localhost:9200/logs-*/_forcemerge?max_num_segments=1"

# Compact indexes
curl -X POST "http://localhost:9200/logs-*/_shrink/logs-compact"
```

---

## Troubleshooting

### âŒ Elasticsearch nÃ£o inicia

```bash
# Verifique logs
docker logs infra-default-elasticsearch

# Verifique permissÃµes
sudo chown -R 1000:1000 /var/lib/docker/volumes/infra-default-elasticsearch_data/

# Reset
docker volume rm infra-devtools_infra-default-elasticsearch_data
```

### âŒ Kibana nÃ£o conecta ao Elasticsearch

```bash
# Verifique conectividade
curl http://elasticsearch:9200

# Verifique configuraÃ§Ã£o
docker logs infra-default-kibana

# Reinicie ambos
docker-compose restart elasticsearch kibana
```

### âŒ Logs nÃ£o aparecem em Kibana

```bash
# Verifique index
make elk-indexes

# Verifique logs do Filebeat
docker logs infra-default-filebeat

# Verifique logs do Logstash
docker logs infra-default-logstash

# Test manual
echo "Test log" | docker exec -i infra-default-logstash bash -c "cat > /tmp/test.log"
```

### âŒ Diskspace cheio

```bash
# Limpar Ã­ndices antigos
make elk-cleanup

# Ou manual
curl -X DELETE "http://localhost:9200/logs-2025.01.01"

# Ver espaÃ§o
curl "http://localhost:9200/_cat/indices?v&h=index,store.size,docs.count"
```

---

## ReferÃªncia RÃ¡pida

### Makefile Commands

```bash
make elk-init       # Inicializar ELK
make elk-verify     # Verificar status
make elk-indexes    # Listar Ã­ndices
make elk-stats      # EstatÃ­sticas
make elk-cleanup    # Limpar antigos
make elk-logs       # Ver logs
```

### URLs

```
Kibana:           http://localhost:5601
Elasticsearch:    http://localhost:9200
Filebeat Metrics: http://localhost:5066
Logstash Metrics: http://localhost:9600
```

### Ãndices

PadrÃ£o: `logs-YYYY.MM.dd`

Exemplos:
- `logs-2025.11.07`
- `logs-2025.11.08`
- `logs-2025.11.09`

---

## Next Steps

1. **Criar Dashboards Personalizados**
   - VÃ¡ em Kibana > Dashboards
   - Criar dashboard customizado
   - Adicionar visualizaÃ§Ãµes

2. **Setup Alertas**
   - Kibana > Stack Management > Alerting
   - Create alert rule
   - Configure notification

3. **IntegraÃ§Ã£o com Grafana**
   - Adicionar Elasticsearch como datasource
   - Importar dashboards

---

<p align="center">
  <b>Logs centralizados = Melhor debugging = Melhor produÃ§Ã£o</b><br>
  <b>ðŸš€ by Kleilson Santos</b>
</p>
